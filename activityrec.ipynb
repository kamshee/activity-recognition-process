{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stroke sensor Health Control data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extraction code modified from CIS-PD: DataPreprocessor2_wTime.ipynb\n",
    "https://github.com/adai2017/CIS_PD/blob/master/DataPreprocessor2_wTime.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import pickle #to save files\n",
    "from itertools import product\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import time\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---Pandas version required to load pickle files is 0.20.1 or greater---\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    if platform.release() == '7':\n",
    "        path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\controls'\n",
    "        folder_path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data'\n",
    "        dict_path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\Data_dict'\n",
    "#        scores_path = r'X:\\CIS-PD Study\\Scores'\n",
    "#        features_path = r'X:\\CIS-PD Study\\FeatureMatrix'\n",
    "#else:\n",
    "#    path = '/Volumes/RTO/CIS-PD Study/Subjects/' #Mac\n",
    "#    folder_path = '/Volumes/RTO/CIS-PD Study/'\n",
    "#    dict_path = '../Data_dict' # Mac local path\n",
    "#    scores_path = '../Scores/' # Mac local path\n",
    "#    features_path = '../FeatureMatrix' # Mac local path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified 'complete' list changing from EventType to Value ???\n",
    "complete= list(['LYING','SITTING','STANDING','WALKING','STAIRS DOWN','STAIRS UP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotations(path):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Processes raw annotations file to extract start / end timestamps and remove unnecessary data\n",
    "#\n",
    "# Inputs:  path - filepath of the subject folder containing annotations.csv\n",
    "#\n",
    "# Outputs: df - dataframe containing list of activities and their start / end timestamps\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    df = pd.read_csv(os.path.join(path, 'annotations.csv'))\n",
    "    del df['Timestamp (ms)']\n",
    "    del df['AnnotationId']\n",
    "    del df['AuthorId']\n",
    "    \n",
    "    # subset Activity Recognition data by partially match EventType string\n",
    "    df = df[df['EventType'].str.match('Activity')]\n",
    "    del d1['EventType']\n",
    "    df.Value = df.Value.shift(-1)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Create Trial column for Value\n",
    "    sorter = set(df.Value.unique().flatten())\n",
    "    sorterIndex = dict(zip(sorter, range(len(sorter))))        \n",
    "    df['Value_Rank'] = df['Value'].map(sorterIndex)\n",
    "    df['Trial'] = df.groupby('Value')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "    del df['Value_Rank']\n",
    "    df = df.reset_index(drop=True).set_index('Value')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a given subject, extracts and separates accelerometer, gyroscope, and \n",
    "#EMG/ECG data into trials and sensor per activity\n",
    "def  extract_data(SubID, path):\n",
    "\n",
    "    ## This is the annotations.csv dataset cleaned\n",
    "    ## Used to match timestamp ranges to the accel, gyro, elec data\n",
    "    timestamps = process_annotations(path)\n",
    "#    timestamps = fix_errors(SubID, timestamps)\n",
    "#    timestamps = add_unstruct_data(timestamps)\n",
    "    \n",
    "    # Creates list of sensor locations from folders within subject's raw data directory\n",
    "    locations = [locs for locs in os.listdir(path) if os.path.isdir(os.path.join(path, locs))]\n",
    "    \n",
    "    # Creates dictionary of empty dataframes to merge all accelerometer, gyroscope, and EMG/ECG data for each sensor\n",
    "    accel = {locs: pd.DataFrame() for locs in locations}\n",
    "    gyro = {locs: pd.DataFrame() for locs in locations}\n",
    "    elec = {locs: pd.DataFrame() for locs in locations}\n",
    "    \n",
    "    # Finds and merges all accelerometer, gyroscope, and EMG/ECG data for each sensor, retains datetime information\n",
    "    for root, dirs, files in os.walk(path, topdown=True):\n",
    "        for filenames in files:\n",
    "            if filenames.endswith('accel.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                accel[location] = accel[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('gyro.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                gyro[location] = gyro[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('elec.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                elec[location] = elec[location].append(temp_df)\n",
    "                \n",
    "#####################################\n",
    "#####################################\n",
    "####### START HERE\n",
    "#####################################\n",
    "#####################################\n",
    "    complete_acts = complete\n",
    "    \n",
    "    # Complete dictionary of all activities\n",
    "    act_dict = {acts: pd.DataFrame() for acts in complete_acts}\n",
    "    \n",
    "    # Populate dictionary keys per activity with every iteration / trial\n",
    "    for activities in complete_acts:\n",
    "        \n",
    "        startSize = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "        \n",
    "        if np.size(startSize) == 1:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)']\n",
    "        else:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)'].values\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)'].values\n",
    "\n",
    "        # Create trial dictionary with each key containing all sensor data related with each activity's trial\n",
    "        trial_dict = {trials: pd.DataFrame() for trials in range(0, np.size(startTimestamp))}\n",
    "\n",
    "        # Populate trial directory keys\n",
    "        for trials in range(0, np.size(startTimestamp)):\n",
    "\n",
    "            if np.size(startSize) == 1:\n",
    "                startTime = startTimestamp\n",
    "                endTime = endTimestamp\n",
    "            else:\n",
    "                startTime = startTimestamp[trials]\n",
    "                endTime = endTimestamp[trials]\n",
    "\n",
    "            # Create sensor location dictionary with each key corresponding to sensor locations\n",
    "            sensor_dict = {locs: pd.DataFrame() for locs in locations}\n",
    "\n",
    "            # Extract sensor data and populate sensor_dict with sensor data\n",
    "            for location in locations:\n",
    "\n",
    "                data = {'accel': pd.DataFrame(), 'gyro': pd.DataFrame(), 'elec': pd.DataFrame()}\n",
    "\n",
    "                if not accel[location].empty:\n",
    "                    accelData = accel[location]\n",
    "                    data['accel'] = accelData[(accelData.index >= startTime) & (accelData.index <= endTime)]  \n",
    " \n",
    "                if not gyro[location].empty:\n",
    "                    gyroData = gyro[location]\n",
    "                    data['gyro'] = gyroData[(gyroData.index >= startTime) & (gyroData.index <= endTime)]\n",
    "                   \n",
    "                if not elec[location].empty:\n",
    "                    elecData = elec[location]\n",
    "                    data['elec'] = elecData[(elecData.index >= startTime) & (elecData.index <= endTime)]\n",
    "                   \n",
    "                sensor_dict[location] = data\n",
    "\n",
    "            trial_dict[trials] = sensor_dict\n",
    "\n",
    "        act_dict[activities] = trial_dict\n",
    "    \n",
    "    return act_dict, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Check code start\n",
    "\n",
    "########################\n",
    "# May need to modify/remove this......\n",
    "    # Is this the timestamp vs the activity timestamp?\n",
    "########################    \n",
    "def gen_unimodal_data(input_dict, side, unimodal_acts=None, shift=50):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Reduces certain activities and subgroup of sensors in act_dict to only include data during active periods\n",
    "# i.e right hand sensor excludes data when left hand is performing task (e.g. supination-pronation)\n",
    "#\n",
    "# Inputs: act_dict - dictionary of both MDS-UPDRS and Motor Assessment activities separated by trial, sensor location, and\n",
    "#                    accelerometer + gyroscope or accelerometer + EMG/ECG data\n",
    "#         unimodal_acts - list of tasks to consider for data reduction, default value is None and uses list generated within\n",
    "#                         function that cycles through all unimodal tasks. Can feed list to only look at specific subset\n",
    "#         shift - shifting value of starting and ending index of reduced data. Default value is 50\n",
    "#\n",
    "# Outputs: act_dict - returns dictionary with appropriate tasks and sensors limited in scope to active data\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    output_dict = copy.deepcopy(input_dict)\n",
    "    \n",
    "    if unimodal_acts and unimodal_acts is not list:\n",
    "        \n",
    "        raise Error(\"unimodal_acts must be of type list\")\n",
    "        \n",
    "    elif not unimodal_acts:\n",
    "        unimodal_acts = list(['Motor #4: Finger to Nose', 'Motor #5: Alternating Hand Movements'])\n",
    "      \n",
    "    for acts in unimodal_acts:\n",
    "\n",
    "        for trials in range(0, len(input_dict[acts].keys())):\n",
    "            \n",
    "            for sensors in input_dict[acts][trials].keys():\n",
    "                \n",
    "                for data in input_dict[acts][trials][sensors].keys():\n",
    "\n",
    "                    index = len(input_dict[acts][trials][sensors][data]);\n",
    "                    \n",
    "                    if side == 'right':\n",
    "                    \n",
    "                        temp_data = input_dict[acts][trials][sensors][data][shift:((index//2)-shift)];\n",
    "                        output_dict[acts][trials][sensors][data] = temp_data;\n",
    "                    \n",
    "                    elif side == 'left':\n",
    "                    \n",
    "                        temp_data = input_dict[acts][trials][sensors][data][((index//2)+shift):(index-shift)];\n",
    "                        output_dict[acts][trials][sensors][data] = temp_data;\n",
    "                    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove????\n",
    "def add_unstruct_data(input_timestamp):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Includes unstructured activity data between tested and timestamped activities/trials in generated act_dict\n",
    "# \n",
    "# Inputs: input_timestamp - timestamp after processing and fix_errors\n",
    "#\n",
    "# Outputs: unstructured_timestamps - timestamp dataframe with start and end timestamps for unstructured\n",
    "#                                    activities. Organized within act_dict as an additional activity\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    timestamps = input_timestamp.loc[input_timestamp.index != 'Heart Rate Variability']\n",
    "    \n",
    "    startTime = []; endTime = []; Cycle = []; Event = [];\n",
    "\n",
    "    for num in range(1,6):\n",
    "        startTime.append(timestamps[timestamps['Cycle']==num]['Stop Timestamp (ms)'].iat[-1])\n",
    "        endTime.append(timestamps[timestamps['Cycle']==(num+1)]['Start Timestamp (ms)'].iat[0])\n",
    "        Cycle.append(num)\n",
    "        Event.append('Unstructured')\n",
    "\n",
    "    d = {'EventType': Event,\n",
    "         'Start Timestamp (ms)': startTime,\n",
    "         'Stop Timestamp (ms)': endTime,\n",
    "         'Cycle': Cycle}\n",
    "\n",
    "    unstruct = pd.DataFrame(data=d, columns=['EventType', 'Start Timestamp (ms)', 'Stop Timestamp (ms)', 'Cycle'])\n",
    "    unstruct = unstruct.set_index('EventType')\n",
    "    \n",
    "    unstructured_timestamps = input_timestamp.append(unstruct)\n",
    "    \n",
    "    return unstructured_timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries from sensor data from all the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(dict_path))\n",
    "#print(len(os.listdir(dict_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all subj data files in repository\n",
    "d = os.listdir(path)\n",
    "f = [filename for filename in d if filename.startswith('HC')] #need to update to skip existing files in /data\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubID = 'HC01'\n",
    "print('Loading Subject ' + SubID + ' Data...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dict, timestamps = extract_data(SubID, os.path.join(path, SubID))\n",
    "print('Extract data complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dict to Pickle file\n",
    "    filename = dict_path+'\\\\'+SubID + 'dict.pkl'\n",
    "    filename = os.path.join(dict_path, SubID + 'dict.pkl')\n",
    "    print(filename)\n",
    "    f = open(filename,'wb')\n",
    "    pickle.dump(act_dict,f)\n",
    "    f.close()\n",
    "    print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data dict for remaining subjects\n",
    "data_all = []\n",
    "for SubID in list(set(f)):\n",
    "    print('Loading Subject ' + SubID + ' Data...')\n",
    "    act_dict, timestamps = extract_data(SubID, os.path.join(path, SubID))\n",
    "    print('Extract data complete.')\n",
    "    #save dict to Pickle file\n",
    "    filename = dict_path+'\\\\'+SubID + 'dict.pkl'\n",
    "    filename = os.path.join(dict_path, SubID + 'dict.pkl')\n",
    "    print(filename)\n",
    "    f = open(filename,'wb')\n",
    "    pickle.dump(act_dict,f)\n",
    "    f.close()\n",
    "    print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore features from individual subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
