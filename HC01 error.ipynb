{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug HC01 processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\n"
     ]
    }
   ],
   "source": [
    "cd Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import pickle #to save files\n",
    "from itertools import product\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import time\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    if platform.release() == '7':\n",
    "        path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\controls'\n",
    "        folder_path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data'\n",
    "        dict_path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\Data_dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List based on Value data of Activity Recognition\n",
    "complete= list(['LYING','SITTING','STANDING','WALKING','STAIRS DOWN','STAIRS UP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data without 'trial' structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotations(path):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Processes raw annotations file to extract start / end timestamps and remove unnecessary data\n",
    "#\n",
    "# Inputs:  path - filepath of the subject folder containing annotations.csv\n",
    "#\n",
    "# Outputs: df - dataframe containing list of activities and their start / end timestamps\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    df = pd.read_csv(os.path.join(path, 'annotations.csv'))\n",
    "    del df['Timestamp (ms)']\n",
    "    del df['AnnotationId']\n",
    "    del df['AuthorId']\n",
    "    \n",
    "    # subset Activity Recognition data by partially match EventType string\n",
    "    df = df[df['EventType'].str.match('Activity')]\n",
    "    del df['EventType']\n",
    "    df.Value = df.Value.shift(-1)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Create Trial column for Value\n",
    "    sorter = set(df.Value.unique().flatten())\n",
    "    sorterIndex = dict(zip(sorter, range(len(sorter))))        \n",
    "    df['Value_Rank'] = df['Value'].map(sorterIndex)\n",
    "    df['Trial'] = df.groupby('Value')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "    del df['Value_Rank']\n",
    "    df = df.reset_index(drop=True).set_index('Value')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying without Trial\n",
    "\n",
    "#For a given subject, extracts and separates accelerometer, gyroscope, and \n",
    "#EMG/ECG data into trials and sensor per activity\n",
    "def  extract_data(SubID, path):\n",
    "\n",
    "    ## This is the annotations.csv dataset cleaned\n",
    "    ## Used to match timestamp ranges to the accel, gyro, elec data\n",
    "    timestamps = process_annotations(path)\n",
    "#    timestamps = fix_errors(SubID, timestamps)\n",
    "#    timestamps = add_unstruct_data(timestamps)\n",
    "    \n",
    "    # Creates list of sensor locations from folders within subject's raw data directory\n",
    "    locations = [locs for locs in os.listdir(path) if os.path.isdir(os.path.join(path, locs))]\n",
    "    \n",
    "    # Creates dictionary of empty dataframes to merge all accelerometer, gyroscope, and EMG/ECG data for each sensor\n",
    "    accel = {locs: pd.DataFrame() for locs in locations}\n",
    "    gyro = {locs: pd.DataFrame() for locs in locations}\n",
    "    elec = {locs: pd.DataFrame() for locs in locations}\n",
    "    \n",
    "    # Finds and merges all accelerometer, gyroscope, and EMG/ECG data for each sensor, retains datetime information\n",
    "    for root, dirs, files in os.walk(path, topdown=True):\n",
    "        for filenames in files:\n",
    "            if filenames.endswith('accel.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                accel[location] = accel[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('gyro.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                gyro[location] = gyro[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('elec.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                elec[location] = elec[location].append(temp_df)\n",
    "                \n",
    "    complete_acts = complete\n",
    "    \n",
    "    # Complete dictionary of all activities\n",
    "    act_dict = {acts: pd.DataFrame() for acts in complete_acts}\n",
    "    \n",
    "    # Populate dictionary keys per activity with every sensor\n",
    "    for activities in complete_acts:\n",
    "        \n",
    "        startSize = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "        \n",
    "        if np.size(startSize) == 1:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)']\n",
    "        else:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)'].values\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)'].values\n",
    "\n",
    "        # Create sensor location dictionary with each key corresponding to sensor locations\n",
    "        sensor_dict = {locs: pd.DataFrame() for locs in locations}\n",
    "\n",
    "        # Extract sensor data and populate sensor_dict with sensor data\n",
    "        for location in locations:\n",
    "            print(location)#######################################\n",
    "\n",
    "            data = {'accel': pd.DataFrame(), 'gyro': pd.DataFrame(), 'elec': pd.DataFrame()}\n",
    "\n",
    "            if not accel[location].empty:\n",
    "                accelData = accel[location]\n",
    "                data['accel'] = accelData[(accelData.index >= startTime) & (accelData.index <= endTime)]  \n",
    "                ###########\n",
    "                ###########\n",
    "                #print(bool(data))\n",
    "                #if not bool(data):\n",
    "                #    data['accel'] = accelData[(accelData.index >= startTimestamp) & (accelData.index <= endTimestamp)]\n",
    "                #    print(bool(data))\n",
    "                #    print('added data') ###########\n",
    "                #else:\n",
    "                #    data['accel'] = data['accel'].append(accelData[(accelData.index >= startTimestamp) & (accelData.index <= endTimestamp)])\n",
    "\n",
    "            if not gyro[location].empty:\n",
    "                gyroData = gyro[location]\n",
    "                data['gyro'] = gyroData[(gyroData.index >= startTimestamp) & (gyroData.index <= endTimestamp)]\n",
    "\n",
    "            if not elec[location].empty:\n",
    "                elecData = elec[location]\n",
    "                data['elec'] = elecData[(elecData.index >= startTimestamp) & (elecData.index <= endTimestamp)]\n",
    "\n",
    "            sensor_dict[location] = data\n",
    "\n",
    "        act_dict[activities] = sensor_dict\n",
    "    \n",
    "    return act_dict, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubID = 'HC02'\n",
    "timestamps = process_annotations(os.path.join(path, SubID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually extract HC01 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path2 = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\HC01test'\n",
    "SubID = 'HC01'\n",
    "path2 = os.path.join(path, SubID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC01\n",
      "Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\controls\n",
      "Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\controls\\HC01\n"
     ]
    }
   ],
   "source": [
    "print(SubID)\n",
    "print(path)\n",
    "print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dict, timestamps = extract_data(SubID, os.path.join(path, SubID))\n",
    "print('Extract data complete.')\n",
    "filename = os.path.join(dict_path2, SubID + 'dict.pkl')\n",
    "with open(filename,'wb') as f:\n",
    "    pickle.dump(act_dict,f)\n",
    "print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = process_annotations(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(dict_path2, SubID + 'dict.pkl')\n",
    "with open(filename,'wb') as f:\n",
    "    pickle.dump(act_dict,f)\n",
    "print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sacrum walking\n",
    "rawdata = act_dict['WALKING']['sacrum']['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HC02 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Pickle file dict\n",
    "subj = 'HC02'\n",
    "f = open(os.path.join(dict_path, subj + 'dict.pkl'), 'rb') # use for C: directory\n",
    "act_dict = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dict['WALKING'][0]['sacrum']['accel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sacrum walking\n",
    "rawdata = act_dict['WALKING'][0]['sacrum']['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sacrum walking\n",
    "rawdata = act_dict['WALKING'][1]['sacrum']['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sacrum walking\n",
    "rawdata = act_dict['WALKING'][2]['sacrum']['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sacrum walking\n",
    "rawdata = act_dict['WALKING'][3]['sacrum']['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sacrum walking - all trials\n",
    "rawdata = act_dict['WALKING'][0]['sacrum']['accel']\n",
    "rawdata = rawdata.append(act_dict['WALKING'][1]['sacrum']['accel'])\n",
    "rawdata = rawdata.append(act_dict['WALKING'][2]['sacrum']['accel'])\n",
    "rawdata = rawdata.append(act_dict['WALKING'][3]['sacrum']['accel'])\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawdata.head(5))\n",
    "print(rawdata.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore features from individual subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...Skip HC01 until error is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Pickle file dict\n",
    "subj = 'HC02'\n",
    "f = open(os.path.join(dict_path, subj + 'dict.pkl'), 'rb')\n",
    "act_dict = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose task, sensor location, data type, and trials\n",
    "\n",
    "#task = 'LYING'\n",
    "#task = 'SITTING'\n",
    "#task = 'STANDING'\n",
    "task = 'WALKING'\n",
    "#task = 'STAIRS DOWN'\n",
    "#task = 'STAIRS UP'\n",
    "\n",
    "#loc = 'bicep_left'\n",
    "#loc = 'bicep_right'\n",
    "#loc = 'biceps_femoris_left'\n",
    "#loc = 'biceps_femoris_right'\n",
    "#loc = 'distal_lateral_shank_left' # has accel and gyro\n",
    "#loc = 'distal_lateral_shank_right' # has accel and gyro\n",
    "#loc = 'gastrocnemius_left'\n",
    "#loc = 'gastrocnemius_right'\n",
    "#loc = 'medial_chest'\n",
    "#loc = 'posterior_forearm_left'\n",
    "#loc = 'posterior_forearm_right'\n",
    "#loc = 'rectus_femoris_left'\n",
    "#loc = 'rectus_femoris_right'\n",
    "loc = 'sacrum' # has accel and gyro\n",
    "#loc = 'tibialis_anterior_left'\n",
    "#loc = 'tibialis_anterior_right'\n",
    "\n",
    "## want a + g\n",
    "sensor = 'accel'\n",
    "#sensor = 'gyro'\n",
    "#sensor = 'elec'\n",
    "\n",
    "trial = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activity dictionary structure (TASK-TRIAL-LOCATION-SENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacrum walking\n",
    "rawdata = act_dict['WALKING'][0]['sacrum']['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = clip_data[0]['accel']\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCO2 walking sacrum accel - all trials\n",
    "# 4295x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = clip_data\n",
    "rawdata.plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clips\n",
    "clip_data = gen_clips(act_dict,task,loc,verbose=True,len_tol=0.95)\n",
    "feature_extraction(clip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
