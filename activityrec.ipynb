{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stroke sensor Health Control data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nolds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7373bd480f3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbutter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwelch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltfilt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnolds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nolds'"
     ]
    }
   ],
   "source": [
    "# Importing the Libraries\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import pickle #to save files\n",
    "from itertools import product\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import time\n",
    "import nolds\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extraction code modified from CIS-PD: DataPreprocessor2_wTime.ipynb\n",
    "#https://github.com/adai2017/CIS_PD/blob/master/DataPreprocessor2_wTime.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---Pandas version required to load pickle files is 0.20.1 or greater---\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    if platform.release() == '7':\n",
    "        path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\controls'\n",
    "        folder_path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data'\n",
    "        dict_path = r'Y:\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\Data_dict'\n",
    "#        scores_path = r'X:\\CIS-PD Study\\Scores'\n",
    "#        features_path = r'X:\\CIS-PD Study\\FeatureMatrix'\n",
    "#else:\n",
    "#    path = '/Volumes/RTO/CIS-PD Study/Subjects/' #Mac\n",
    "#    folder_path = '/Volumes/RTO/CIS-PD Study/'\n",
    "#    dict_path = '../Data_dict' # Mac local path\n",
    "#    scores_path = '../Scores/' # Mac local path\n",
    "#    features_path = '../FeatureMatrix' # Mac local path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified 'complete' list changing from EventType to Value\n",
    "complete= list(['LYING','SITTING','STANDING','WALKING','STAIRS DOWN','STAIRS UP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotations(path):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Processes raw annotations file to extract start / end timestamps and remove unnecessary data\n",
    "#\n",
    "# Inputs:  path - filepath of the subject folder containing annotations.csv\n",
    "#\n",
    "# Outputs: df - dataframe containing list of activities and their start / end timestamps\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    df = pd.read_csv(os.path.join(path, 'annotations.csv'))\n",
    "    del df['Timestamp (ms)']\n",
    "    del df['AnnotationId']\n",
    "    del df['AuthorId']\n",
    "    \n",
    "    # subset Activity Recognition data by partially match EventType string\n",
    "    df = df[df['EventType'].str.match('Activity')]\n",
    "    del d1['EventType']\n",
    "    df.Value = df.Value.shift(-1)\n",
    "    df = df.dropna()\n",
    "    trial = ['trial 1','trial 1','trial 1','trial 1','trial 2','trial 1','trial 1','trial 3','trial 2','trial 3','trial 4','trial 2']\n",
    "    df['trial'] = trial\n",
    "    \n",
    "    ##########################################\n",
    "    # ??? what does this do?\n",
    "#    sorter = set(df.EventType.unique().flatten())\n",
    "#    sorterIndex = dict(zip(sorter, range(len(sorter))))        \n",
    "#    df['EventType_Rank'] = df['EventType'].map(sorterIndex)\n",
    "#    df['Cycle'] = df.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "#    del df['EventType_Rank']\n",
    "#    df[df['EventType'].str.contains('Heart')] = df[df['EventType'].str.contains('Heart')].replace(to_replace={'Cycle': {1: 'NaN', 2: 'NaN', 3: 'NaN', 4: 'NaN'}})\n",
    "#    df = df.reset_index(drop=True).set_index('EventType')\n",
    "    \n",
    "    # \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a given subject, extracts and separates accelerometer, gyroscope, and \n",
    "#EMG/ECG data into trials and sensor per activity\n",
    "def  extract_data(SubID, path):\n",
    "\n",
    "    ## This is the annotations.csv dataset cleaned\n",
    "    ## used to match timestamp ranges to the accel, gyro, elec data\n",
    "    timestamps = process_annotations(path)\n",
    "#    timestamps = fix_errors(SubID, timestamps)\n",
    "#    timestamps = add_unstruct_data(timestamps)\n",
    "    \n",
    "    # Creates list of sensor locations from folders within subject's raw data directory\n",
    "    locations = [locs for locs in os.listdir(path) if os.path.isdir(os.path.join(path, locs))]\n",
    "    \n",
    "    # Creates dictionary of empty dataframes to merge all accelerometer, gyroscope, and EMG/ECG data for each sensor\n",
    "    accel = {locs: pd.DataFrame() for locs in locations}\n",
    "    gyro = {locs: pd.DataFrame() for locs in locations}\n",
    "    elec = {locs: pd.DataFrame() for locs in locations}\n",
    "    \n",
    "    # Finds and merges all accelerometer, gyroscope, and EMG/ECG data for each sensor, retains datetime information\n",
    "    for root, dirs, files in os.walk(path, topdown=True):\n",
    "        for filenames in files:\n",
    "            if filenames.endswith('accel.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                accel[location] = accel[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('gyro.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                gyro[location] = gyro[location].append(temp_df)\n",
    "\n",
    "            elif filenames.endswith('elec.csv'):\n",
    "                p = pathlib.Path(os.path.join(root, filenames))\n",
    "                location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "                temp_df = pd.read_csv(p).set_index('Timestamp (ms)')\n",
    "                elec[location] = elec[location].append(temp_df)\n",
    "                \n",
    "    # ??? Are any subjects missing data?\n",
    "#####################################\n",
    "#####################################\n",
    "####### START HERE\n",
    "#####################################\n",
    "#####################################\n",
    "    complete_acts = complete\n",
    "    \n",
    "    # Complete dictionary of all activities\n",
    "    act_dict = {acts: pd.DataFrame() for acts in complete_acts}\n",
    "    \n",
    "    # Populate dictionary keys per activity with every iteration / trial\n",
    "    for activities in complete_acts:\n",
    "        \n",
    "        startSize = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "        \n",
    "        if np.size(startSize) == 1:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)']\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)']\n",
    "        else:\n",
    "            startTimestamp = timestamps.loc[activities, 'Start Timestamp (ms)'].values\n",
    "            endTimestamp = timestamps.loc[activities, 'Stop Timestamp (ms)'].values\n",
    "\n",
    "        # Create trial dictionary with each key containing all sensor data related with each activity's trial\n",
    "        trial_dict = {trials: pd.DataFrame() for trials in range(0, np.size(startTimestamp))}\n",
    "\n",
    "        # Populate trial directory keys\n",
    "        for trials in range(0, np.size(startTimestamp)):\n",
    "\n",
    "            if np.size(startSize) == 1:\n",
    "                startTime = startTimestamp\n",
    "                endTime = endTimestamp\n",
    "            else:\n",
    "                startTime = startTimestamp[trials]\n",
    "                endTime = endTimestamp[trials]\n",
    "\n",
    "            # Create sensor location dictionary with each key corresponding to sensor locations\n",
    "            sensor_dict = {locs: pd.DataFrame() for locs in locations}\n",
    "\n",
    "            # Extract sensor data and populate sensor_dict with sensor data\n",
    "            for location in locations:\n",
    "\n",
    "                data = {'accel': pd.DataFrame(), 'gyro': pd.DataFrame(), 'elec': pd.DataFrame()}\n",
    "\n",
    "                if not accel[location].empty:\n",
    "                    accelData = accel[location]\n",
    "                    data['accel'] = accelData[(accelData.index >= startTime) & (accelData.index <= endTime)]  \n",
    "\n",
    "# Removed code \n",
    "                if not gyro[location].empty:\n",
    "                    gyroData = gyro[location]\n",
    "                    data['gyro'] = gyroData[(gyroData.index >= startTime) & (gyroData.index <= endTime)]\n",
    "\n",
    "# Removed code                    \n",
    "                if not elec[location].empty:\n",
    "                    elecData = elec[location]\n",
    "                    data['elec'] = elecData[(elecData.index >= startTime) & (elecData.index <= endTime)]\n",
    "# Removed code                    \n",
    "                sensor_dict[location] = data\n",
    "\n",
    "            trial_dict[trials] = sensor_dict\n",
    "\n",
    "        act_dict[activities] = trial_dict\n",
    "    \n",
    "    return act_dict, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Check code start\n",
    "\n",
    "########################\n",
    "# May need to modify/remove this......\n",
    "    # Is this the timestamp vs the activity timestamp?\n",
    "########################    \n",
    "def gen_unimodal_data(input_dict, side, unimodal_acts=None, shift=50):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Reduces certain activities and subgroup of sensors in act_dict to only include data during active periods\n",
    "# i.e right hand sensor excludes data when left hand is performing task (e.g. supination-pronation)\n",
    "#\n",
    "# Inputs: act_dict - dictionary of both MDS-UPDRS and Motor Assessment activities separated by trial, sensor location, and\n",
    "#                    accelerometer + gyroscope or accelerometer + EMG/ECG data\n",
    "#         unimodal_acts - list of tasks to consider for data reduction, default value is None and uses list generated within\n",
    "#                         function that cycles through all unimodal tasks. Can feed list to only look at specific subset\n",
    "#         shift - shifting value of starting and ending index of reduced data. Default value is 50\n",
    "#\n",
    "# Outputs: act_dict - returns dictionary with appropriate tasks and sensors limited in scope to active data\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    output_dict = copy.deepcopy(input_dict)\n",
    "    \n",
    "    if unimodal_acts and unimodal_acts is not list:\n",
    "        \n",
    "        raise Error(\"unimodal_acts must be of type list\")\n",
    "        \n",
    "    elif not unimodal_acts:\n",
    "        unimodal_acts = list(['Motor #4: Finger to Nose', 'Motor #5: Alternating Hand Movements'])\n",
    "      \n",
    "    for acts in unimodal_acts:\n",
    "\n",
    "        for trials in range(0, len(input_dict[acts].keys())):\n",
    "            \n",
    "            for sensors in input_dict[acts][trials].keys():\n",
    "                \n",
    "                for data in input_dict[acts][trials][sensors].keys():\n",
    "\n",
    "                    index = len(input_dict[acts][trials][sensors][data]);\n",
    "                    \n",
    "                    if side == 'right':\n",
    "                    \n",
    "                        temp_data = input_dict[acts][trials][sensors][data][shift:((index//2)-shift)];\n",
    "                        output_dict[acts][trials][sensors][data] = temp_data;\n",
    "                    \n",
    "                    elif side == 'left':\n",
    "                    \n",
    "                        temp_data = input_dict[acts][trials][sensors][data][((index//2)+shift):(index-shift)];\n",
    "                        output_dict[acts][trials][sensors][data] = temp_data;\n",
    "                    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove????\n",
    "def add_unstruct_data(input_timestamp):\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "# Includes unstructured activity data between tested and timestamped activities/trials in generated act_dict\n",
    "# \n",
    "# Inputs: input_timestamp - timestamp after processing and fix_errors\n",
    "#\n",
    "# Outputs: unstructured_timestamps - timestamp dataframe with start and end timestamps for unstructured\n",
    "#                                    activities. Organized within act_dict as an additional activity\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    timestamps = input_timestamp.loc[input_timestamp.index != 'Heart Rate Variability']\n",
    "    \n",
    "    startTime = []; endTime = []; Cycle = []; Event = [];\n",
    "\n",
    "    for num in range(1,6):\n",
    "        startTime.append(timestamps[timestamps['Cycle']==num]['Stop Timestamp (ms)'].iat[-1])\n",
    "        endTime.append(timestamps[timestamps['Cycle']==(num+1)]['Start Timestamp (ms)'].iat[0])\n",
    "        Cycle.append(num)\n",
    "        Event.append('Unstructured')\n",
    "\n",
    "    d = {'EventType': Event,\n",
    "         'Start Timestamp (ms)': startTime,\n",
    "         'Stop Timestamp (ms)': endTime,\n",
    "         'Cycle': Cycle}\n",
    "\n",
    "    unstruct = pd.DataFrame(data=d, columns=['EventType', 'Start Timestamp (ms)', 'Stop Timestamp (ms)', 'Cycle'])\n",
    "    unstruct = unstruct.set_index('EventType')\n",
    "    \n",
    "    unstructured_timestamps = input_timestamp.append(unstruct)\n",
    "    \n",
    "    return unstructured_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix Error Functions\n",
    "def fix_errors(participant, timestamps):\n",
    "#input: 4 digit participant ID\n",
    "# if debugFlag = 1, will execute merge function\n",
    "#Output: ErrorList - A list of the errors needed to be fixed for the participant\n",
    "#        timestamps - The dataFrame with the errors corrected for the participant\n",
    "#        errordf - The dataFrame containing the remaining errors less the ones just fixed\n",
    "\n",
    "    participant = int(participant) #convert to int, input SubID is a str\n",
    "    errordf = pd.read_excel(os.path.join(folder_path, 'PD_errorWorkbook.xlsx'))\n",
    "    errPar = errordf[errordf['Participant'] == participant]\n",
    "    errorActivity = (errPar['Activity'])\n",
    "    error = errPar['Error']\n",
    "    cycle = errPar['Cycle']\n",
    "    day = errPar['Day']\n",
    "    time = errPar['Time Adjusted (sec)']\n",
    "    desc = errPar['Type']\n",
    "    errorAndActivity = errPar[['Error','Activity']]\n",
    "    \n",
    "    # Hard coded relabel for one activity in Subject 1049's timestamps\n",
    "    if participant == 1049:\n",
    "        for i in range(0,len(timestamps)-1):\n",
    "            row = timestamps.iloc[i]\n",
    "        \n",
    "            if timestamps.index[i] == 'MDS-UPDRS #6: Arising from Chair' and row['Start Timestamp (ms)'] == 1505757980933:\n",
    "                timestamps.reset_index(inplace=True)\n",
    "                #timestamps.set_value(i, 'EventType', 'Motor #6: Sit to Stand')\n",
    "                #.set_value is deprecated as of pandas 21.0, .at used instead for label-based\n",
    "                timestamps.at[i, 'EventType'] = 'Motor #6: Sit to Stand'\n",
    "                timestamps.set_index('EventType', inplace=True)\n",
    "    \n",
    "    for a in range(0,len(error)):\n",
    "        errAct = (errorActivity.iloc[a])\n",
    "        errType = (error.iloc[a])\n",
    "        errCycle = (cycle.iloc[a])\n",
    "        errTime = (time.iloc[a])\n",
    "        errDesc = (desc.iloc[a])\n",
    "        errDay = (day.iloc[a])\n",
    "        if errDay == 'Day 2':\n",
    "            if 'MDS' in errAct:\n",
    "                errCycle = errCycle + 2\n",
    "            elif 'Motor' in errAct:\n",
    "                errCycle = errCycle + 5\n",
    "\n",
    "        if errType == 'Merge':\n",
    "            timestamps = fix_merge(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "\n",
    "        elif errType == 'Late':\n",
    "            timestamps = fix_late(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "\n",
    "        elif errType == 'Early':\n",
    "            timestamps = fix_early(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "\n",
    "        elif errType == 'Duplicate':\n",
    "            timestamps = fix_duplicate(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay,participant)\n",
    "\n",
    "        elif errType == 'Split':\n",
    "            timestamps = fix_split(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "            \n",
    "    for a in range(0,len(error)):\n",
    "        errAct = (errorActivity.iloc[a])\n",
    "        errType = (error.iloc[a])\n",
    "        errCycle = (cycle.iloc[a])\n",
    "        errTime = (time.iloc[a])\n",
    "        errDesc = (desc.iloc[a])\n",
    "        errDay = (day.iloc[a])\n",
    "        \n",
    "        if errType == 'Absent':\n",
    "            timestamps = fix_absent(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay)\n",
    "    \n",
    "    \n",
    "    tempappend = errordf.loc[errPar.index.values]\n",
    "    #fixdf = fixdf.append(tempappend)\n",
    "    errordf = errordf.drop(errPar.index.values)\n",
    "    \n",
    "    print('Subject ' + str(participant) + ' had ' + str(len(error)) + ' errors fixed.')\n",
    "\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_late(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "# subtracts time from the beginning or ending timestamp of the designated activity\n",
    "\n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        startRow = timestamps.iloc[i]\n",
    "        if timestamps.index[i] == errAct and startRow['Cycle'] == errCycle:\n",
    "            errorLocation = i\n",
    "      \n",
    "            if errType == 'End':\n",
    "                startTime = startRow['Stop Timestamp (ms)']\n",
    "                startTime = startTime - (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "        \n",
    "            else:\n",
    "                startTime = startRow['Start Timestamp (ms)']\n",
    "                # print(startRow)\n",
    "                # print(startTime)\n",
    "                startTime = startTime - (errTime*1000)\n",
    "                # print(errTime)\n",
    "                # print(startTime)\n",
    "                ii = timestamps.columns.get_loc('Start Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "     \n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_early(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "# adds time to the beginning or ending timestamp of the designated activity\n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        startRow = timestamps.iloc[i]\n",
    "        \n",
    "        if timestamps.index[i] == errAct and startRow['Cycle'] == errCycle:\n",
    "            errorLocation = i\n",
    "            \n",
    "            if errType == 'End':\n",
    "                startTime = startRow[1]\n",
    "                startTime = startTime + (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "\n",
    "            else:\n",
    "                startTime = startRow[0]\n",
    "                startTime = startTime + (errTime*1000)\n",
    "                ii = timestamps.columns.get_loc('Start Timestamp (ms)')\n",
    "                # timestamps.set_value(i,ii,startTime,takeable=True)\n",
    "                timestamps.iat[i,ii] = startTime\n",
    "                # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_merge(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "\n",
    "    for i in range(0,len(timestamps)-2):\n",
    "        nextRow = timestamps.iloc[i+1]\n",
    "        startRow = timestamps.iloc[i]\n",
    "\n",
    "        if timestamps.index[i] == errAct and startRow['Cycle'] == errCycle:\n",
    "            timeEnd = nextRow['Stop Timestamp (ms)']\n",
    "            ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "            # timestamps.set_value(i,ii,timeEnd,takeable=True)\n",
    "            timestamps.iat[i,ii] = timeEnd\n",
    "            # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "            timestamps = pd.concat([timestamps.iloc[:(i+1)],timestamps.iloc[(i+2):]])\n",
    "\n",
    "        timestamps.reset_index(inplace=True)\n",
    "        timestamps['Cycle'] = timestamps.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "        timestamps.set_index('EventType',inplace=True)\n",
    "\n",
    "    return timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_split(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "\n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        row = timestamps.iloc[i]\n",
    "        \n",
    "        if timestamps.index[i] == errAct and row['Cycle'] == errCycle:\n",
    "            timeStart1 = row['Start Timestamp (ms)']\n",
    "            timeEnd2 = row['Stop Timestamp (ms)']\n",
    "            timeChange = errTime\n",
    "            timeEnd1 = timeStart1 + timeChange\n",
    "            timeStart2 = timeEnd1\n",
    "            idx = complete.index(errAct)\n",
    "            ErrorActivity2 = complete[idx+1]\n",
    "            ii = timestamps.columns.get_loc('Stop Timestamp (ms)')\n",
    "            # timestamps.set_value(i,ii,timeEnd1,takeable=True)\n",
    "            timestamps.iat[i,ii] = timeEnd1\n",
    "            # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "            line = pd.DataFrame({\"Start Timestamp (ms)\":timeEnd1,\"Stop Timestamp (ms)\":timeEnd2,\"Cycle\":errCycle},index=[ErrorActivity2])\n",
    "            timestamps = pd.concat([timestamps.iloc[:(i+1)],line,timestamps.iloc[(i+1):]])\n",
    "            \n",
    "            timestamps.reset_index(inplace=True)\n",
    "            colnames = timestamps.columns.tolist()\n",
    "            colnames[colnames.index('index')] = 'EventType'\n",
    "            timestamps.columns = colnames\n",
    "            timestamps['Cycle'] = timestamps.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "            timestamps.set_index('EventType',inplace=True)\n",
    "           \n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_duplicate(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay,participant):\n",
    "\n",
    "    for i in range(0,len(timestamps)-2):\n",
    "        row = timestamps.iloc[i]\n",
    "        if participant == 1054 and timestamps.index[i] == 'Motor #8: Typing on a Computer':\n",
    "            if timestamps.index[i] == errAct and row['Cycle'] == errCycle+1:\n",
    "                timestamps = pd.concat([timestamps.iloc[:(i)],timestamps.iloc[(i+1):]])\n",
    "            \n",
    "        elif timestamps.index[i] == errAct and row['Cycle'] == errCycle:\n",
    "            timestamps = pd.concat([timestamps.iloc[:i],timestamps.iloc[(i+1):]])\n",
    "            \n",
    "    timestamps.reset_index(inplace=True)\n",
    "    timestamps['Cycle'] = timestamps.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "    timestamps.set_index('EventType',inplace=True)\n",
    "\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_absent(timestamps,errType,errAct,errCycle,errTime,errDesc,errDay):\n",
    "    \n",
    "    for i in range(0,len(timestamps)-1):\n",
    "        row = timestamps.iloc[i]\n",
    "        \n",
    "        if timestamps.index[i] == errAct and row['Cycle'] == errCycle and errDay != 'Day 2':\n",
    "\n",
    "            for j in range(i-1,len(timestamps)-1):\n",
    "                row = timestamps.iloc[j]\n",
    "                \n",
    "                if timestamps.index[j] == errAct:\n",
    "                    cyclenum = row['Cycle']\n",
    "                    newCycle = cyclenum + 1\n",
    "                    ii = timestamps.columns.get_loc('Cycle')\n",
    "                    # timestamps.set_value(j,ii,newCycle,takeable=True)\n",
    "                    timestamps.iat[j,ii] = newCycle\n",
    "                    # set_value is deprecated as of pandas 21.0, .iat used instead for position-based\n",
    "    \n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errordf = pd.read_excel(os.path.join(folder_path, 'PD_errorWorkbook.xlsx'))\n",
    "#errordf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's this??????\n",
    "os.listdir(path + '/1020/anterior_thigh_left/d5la7wz0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries from sensor data from all the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(dict_path))\n",
    "print(len(os.listdir(dict_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HC20', 'HC26', 'HC13', 'HC06', 'HC28', 'HC01', 'HC30', 'HC05', 'HC08', 'HC09', 'HC07', 'HC27', 'HC22', 'HC33', 'HC21', 'HC25', 'HC04', 'HC11', 'HC24', 'HC18', 'HC14', 'HC17', 'HC31', 'HC03', 'HC15', 'HC29', 'HC10', 'HC12', 'HC19', 'HC32', 'HC16', 'HC23', 'HC02']\n"
     ]
    }
   ],
   "source": [
    "#all subj data files in repository\n",
    "d = os.listdir(path)\n",
    "f = [filename for filename in d if filename.startswith('HC')] #need to update to skip existing files in /data\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Subject HC01 Data...\n"
     ]
    }
   ],
   "source": [
    "SubID = 'HC01'\n",
    "print('Loading Subject ' + SubID + ' Data...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [LYING] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1505\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1506\u001b[1;33m                     \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1507\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1500\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1501\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [LYING] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1f0968fc7e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mact_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSubID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSubID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Extract data complete.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e9cab3a9e20f>\u001b[0m in \u001b[0;36mextract_data\u001b[1;34m(SubID, path)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mactivities\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomplete_acts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mstartSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactivities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Start Timestamp (ms)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartSize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1512\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lu-rto\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[0;32m   1500\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1501\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [LYING] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "act_dict, timestamps = extract_data(SubID, os.path.join(path, SubID))\n",
    "print('Extract data complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dict to Pickle file\n",
    "    filename = dict_path+'\\\\'+SubID + 'dict.pkl'\n",
    "    filename = os.path.join(dict_path, SubID + 'dict.pkl')\n",
    "    print(filename)\n",
    "    f = open(filename,'wb')\n",
    "    pickle.dump(act_dict,f)\n",
    "    f.close()\n",
    "    print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data dict for remaining subjects\n",
    "data_all = []\n",
    "for SubID in list(set(f)):\n",
    "    print('Loading Subject ' + SubID + ' Data...')\n",
    "    act_dict, timestamps = extract_data(SubID, os.path.join(path, SubID))\n",
    "    print('Extract data complete.')\n",
    "    #save dict to Pickle file\n",
    "    filename = dict_path+'\\\\'+SubID + 'dict.pkl'\n",
    "    filename = os.path.join(dict_path, SubID + 'dict.pkl')\n",
    "    print(filename)\n",
    "    f = open(filename,'wb')\n",
    "    pickle.dump(act_dict,f)\n",
    "    f.close()\n",
    "    print(filename + ' ' + 'File Saved\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore features from individual subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
