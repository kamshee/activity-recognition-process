{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test feature_extraction131(clip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import pickle\n",
    "from itertools import product\n",
    "from scipy.stats import skew, kurtosis, pearsonr, iqr, zscore\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "# import nolds\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# from PreprocessFcns import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    if platform.release() == '10':\n",
    "        path = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\controls'\n",
    "        folder_path = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\Data\\biostamp_data'\n",
    "        dict_path = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\Data_dict'\n",
    "        features_path = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\FeatureMatrix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with HC02 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use context manager to load pickle file\n",
    "dict_path2 = r'//FS2.smpp.local\\RTO\\Inpatient Sensors -Stroke\\Data\\biostamp_data\\Data_dict'\n",
    "subj = 'HC02'\n",
    "filename = os.path.join(dict_path2, subj + 'dict.pkl')\n",
    "with open(filename,'rb') as filename:\n",
    "    act_dict = pickle.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract full recording\n",
    "DataPreprocessor2_wTime.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose task, location\n",
    "task = 'WALKING'\n",
    "loc = 'sacrum'\n",
    "# sensor = 'accel'\n",
    "# trial = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WALKING  sensortype = accel - trial 0\n",
      "WALKING  sensortype = gyro - trial 0\n",
      "WALKING  sensortype = accel - trial 1\n",
      "WALKING  sensortype = gyro - trial 1\n",
      "WALKING  sensortype = accel - trial 2\n",
      "WALKING  sensortype = gyro - trial 2\n",
      "WALKING  sensortype = accel - trial 3\n",
      "WALKING  sensortype = gyro - trial 3\n"
     ]
    }
   ],
   "source": [
    "#clipsize=0 extracts full recordings\n",
    "clip_data = gen_clips_merged(act_dict,task,loc,clipsize=0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction using feature_extraction131()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_clip = clip_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction131(copy_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanX_acc</th>\n",
       "      <th>meanY_acc</th>\n",
       "      <th>meanZ_acc</th>\n",
       "      <th>rangeX_acc</th>\n",
       "      <th>rangeY_acc</th>\n",
       "      <th>rangeZ_acc</th>\n",
       "      <th>iqrX_acc</th>\n",
       "      <th>iqrY_acc</th>\n",
       "      <th>iqrZ_acc</th>\n",
       "      <th>stddev_X_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>meanpower_bin11_z_acc</th>\n",
       "      <th>meanpower_bin12_z_acc</th>\n",
       "      <th>meanpower_bin13_z_acc</th>\n",
       "      <th>meanpower_bin14_z_acc</th>\n",
       "      <th>meanpower_bin15_z_acc</th>\n",
       "      <th>meanpower_bin16_z_acc</th>\n",
       "      <th>meanpower_bin17_z_acc</th>\n",
       "      <th>meanpower_bin18_z_acc</th>\n",
       "      <th>meanpower_bin19_z_acc</th>\n",
       "      <th>meanpower_bin20_z_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.028107</td>\n",
       "      <td>0.981632</td>\n",
       "      <td>0.282775</td>\n",
       "      <td>0.717174</td>\n",
       "      <td>0.941787</td>\n",
       "      <td>0.74696</td>\n",
       "      <td>0.155093</td>\n",
       "      <td>0.272526</td>\n",
       "      <td>0.214237</td>\n",
       "      <td>0.117967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.028708</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanX_acc  meanY_acc  meanZ_acc  rangeX_acc  rangeY_acc  rangeZ_acc  \\\n",
       "0  -0.028107   0.981632   0.282775    0.717174    0.941787     0.74696   \n",
       "\n",
       "   iqrX_acc  iqrY_acc  iqrZ_acc  stddev_X_acc          ...            \\\n",
       "0  0.155093  0.272526  0.214237      0.117967          ...             \n",
       "\n",
       "   meanpower_bin11_z_acc  meanpower_bin12_z_acc  meanpower_bin13_z_acc  \\\n",
       "0                0.00056               0.028708               0.003797   \n",
       "\n",
       "   meanpower_bin14_z_acc  meanpower_bin15_z_acc  meanpower_bin16_z_acc  \\\n",
       "0               0.000316               0.000647               0.006482   \n",
       "\n",
       "   meanpower_bin17_z_acc  meanpower_bin18_z_acc  meanpower_bin19_z_acc  \\\n",
       "0               0.002114               0.000556               0.000478   \n",
       "\n",
       "   meanpower_bin20_z_acc  \n",
       "0               0.000332  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_clip[0]['accel']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanX_gyr</th>\n",
       "      <th>meanY_gyr</th>\n",
       "      <th>meanZ_gyr</th>\n",
       "      <th>rangeX_gyr</th>\n",
       "      <th>rangeY_gyr</th>\n",
       "      <th>rangeZ_gyr</th>\n",
       "      <th>iqrX_gyr</th>\n",
       "      <th>iqrY_gyr</th>\n",
       "      <th>iqrZ_gyr</th>\n",
       "      <th>stddev_X_gyr</th>\n",
       "      <th>...</th>\n",
       "      <th>meanpower_bin11_z_gyr</th>\n",
       "      <th>meanpower_bin12_z_gyr</th>\n",
       "      <th>meanpower_bin13_z_gyr</th>\n",
       "      <th>meanpower_bin14_z_gyr</th>\n",
       "      <th>meanpower_bin15_z_gyr</th>\n",
       "      <th>meanpower_bin16_z_gyr</th>\n",
       "      <th>meanpower_bin17_z_gyr</th>\n",
       "      <th>meanpower_bin18_z_gyr</th>\n",
       "      <th>meanpower_bin19_z_gyr</th>\n",
       "      <th>meanpower_bin20_z_gyr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.951188</td>\n",
       "      <td>-10.61773</td>\n",
       "      <td>-1.893648</td>\n",
       "      <td>57.007706</td>\n",
       "      <td>189.88327</td>\n",
       "      <td>180.422668</td>\n",
       "      <td>16.876478</td>\n",
       "      <td>36.652172</td>\n",
       "      <td>32.227055</td>\n",
       "      <td>11.32982</td>\n",
       "      <td>...</td>\n",
       "      <td>7.854145</td>\n",
       "      <td>4.565918</td>\n",
       "      <td>1.258525</td>\n",
       "      <td>4.35949</td>\n",
       "      <td>1.32924</td>\n",
       "      <td>0.692294</td>\n",
       "      <td>1.598647</td>\n",
       "      <td>24.72431</td>\n",
       "      <td>9.249282</td>\n",
       "      <td>1.61767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanX_gyr  meanY_gyr  meanZ_gyr  rangeX_gyr  rangeY_gyr  rangeZ_gyr  \\\n",
       "0   1.951188  -10.61773  -1.893648   57.007706   189.88327  180.422668   \n",
       "\n",
       "    iqrX_gyr   iqrY_gyr   iqrZ_gyr  stddev_X_gyr          ...            \\\n",
       "0  16.876478  36.652172  32.227055      11.32982          ...             \n",
       "\n",
       "   meanpower_bin11_z_gyr  meanpower_bin12_z_gyr  meanpower_bin13_z_gyr  \\\n",
       "0               7.854145               4.565918               1.258525   \n",
       "\n",
       "   meanpower_bin14_z_gyr  meanpower_bin15_z_gyr  meanpower_bin16_z_gyr  \\\n",
       "0                4.35949                1.32924               0.692294   \n",
       "\n",
       "   meanpower_bin17_z_gyr  meanpower_bin18_z_gyr  meanpower_bin19_z_gyr  \\\n",
       "0               1.598647               24.72431               9.249282   \n",
       "\n",
       "   meanpower_bin20_z_gyr  \n",
       "0                1.61767  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_clip[0]['gyro']['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed len tolerance to 0.95 since some clips are < 10 sec\n",
    "def gen_clips_merged(act_dict,task,location,clipsize=10000,overlap=0.9,verbose=False,startTS=0,endTS=1,\n",
    "              len_tol=0.95,resample=False):\n",
    "    \"\"\"\n",
    "    Extract clips and merge into 1 clip for accelerometer and gyro data (allows selecting start and end fraction)\n",
    "    len_tol is the % of the intended clipsize below which clip is not used\n",
    "    \n",
    "    :param clipsize 10000 = 10 sec\n",
    "    :param overlap=0.9 for 90% overlap b/n clips\n",
    "    :param len_tol=1.0, want complete 10 sec clips\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    clip_data = {} #the dictionary with clips\n",
    "\n",
    "    for trial in act_dict[task].keys():\n",
    "        clip_data[trial] = {}\n",
    "\n",
    "        for s in ['accel','gyro']:\n",
    "\n",
    "            if verbose:\n",
    "                print(task,' sensortype = %s - trial %d'%(s,trial))\n",
    "            #create clips and store in a list\n",
    "            rawdata = act_dict[task][trial][location][s]\n",
    "            if rawdata.empty is True: #skip if no data for current sensor\n",
    "                continue\n",
    "            #reindex time (relative to start)\n",
    "            idx = rawdata.index\n",
    "            idx = idx-idx[0]\n",
    "            rawdata.index = idx\n",
    "            #choose to create clips only on a fraction of the data (0<[startTS,endTS]<1)\n",
    "            if (startTS > 0) | (endTS < 1):\n",
    "                rawdata = rawdata.iloc[round(startTS*len(rawdata)):round(endTS*len(rawdata)),:]\n",
    "                #reindex time (relative to start)\n",
    "                idx = rawdata.index\n",
    "                idx = idx-idx[0]\n",
    "                rawdata.index = idx\n",
    "            #create clips data\n",
    "            deltat = np.median(np.diff(rawdata.index))\n",
    "            clips = []\n",
    "            #use entire recording\n",
    "            if clipsize == 0:\n",
    "                clips.append(rawdata)\n",
    "            #take clips\n",
    "            else:\n",
    "                idx = np.arange(0,rawdata.index[-1],clipsize*(1-overlap))\n",
    "                for i in idx:\n",
    "                    c = rawdata[(rawdata.index>=i) & (rawdata.index<i+clipsize)]\n",
    "                    #keep/append clips that are 10 sec, else discard those that don't meet length\n",
    "                    #tolerance\n",
    "                    ## clip len tolerance > 9.5 sec\n",
    "                    if len(c) > len_tol*int(clipsize/deltat):\n",
    "                        # try concat instead of append to make one list\n",
    "                        # check index, if increases like 0, 32, 64, etc then great, otherwise\n",
    "                        # reindex c before extending?\n",
    "                        clips.append(c)\n",
    "\n",
    "            # merge all clips into one\n",
    "            # cycle through each list element, reindex\n",
    "            if len(clips)>1:\n",
    "#                 finalclip = []\n",
    "                for x in range(len(clips)):\n",
    "                    if x==0:\n",
    "                        clips.append(clips[0])\n",
    "                    else:\n",
    "                        # reindex\n",
    "                        idx2 = clips[x].index\n",
    "                        idx2 = idx2-idx2[0]+32+clips[x-1].index[-1]\n",
    "                        clips[x].index = idx2\n",
    "                        # merge into list of dataframes\n",
    "                        clips.append(clips[x])\n",
    "    \n",
    "            # merge into one dataframe\n",
    "            try:\n",
    "                oneclip = pd.concat(clips)\n",
    "            except:\n",
    "                print('Check len_tol in gen_clips_merged function.')\n",
    "            # reset clips\n",
    "            clips = []\n",
    "            clips.append(oneclip)\n",
    "    \n",
    "            #store clip length\n",
    "            #store the length of each clip\n",
    "            clip_len = [clips[c].index[-1]-clips[c].index[0] for c in range(len(clips))] \n",
    "            #assemble in dict\n",
    "            clip_data[trial][s] = {'data':clips, 'clip_len':clip_len}\n",
    "\n",
    "    return clip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_spectra_welch_axis(rawdata,fm,fM):\n",
    "    \"\"\"Compute PSD on each axis then combine into a dataframe\"\"\"\n",
    "    x = rawdata.iloc[:,0]\n",
    "    y = rawdata.iloc[:,1]\n",
    "    z = rawdata.iloc[:,2]\n",
    "    n = len(x) #number of samples in clip\n",
    "    Fs = np.mean(1/(np.diff(x.index)/1000)) #sampling rate in clip\n",
    "    fx,Pxx_denX = welch(x,Fs,nperseg=min(256,n))\n",
    "    fy,Pxx_denY = welch(y,Fs,nperseg=min(256,n))\n",
    "    fz,Pxx_denZ = welch(z,Fs,nperseg=min(256,n))\n",
    "    #return PSD in desired interval of freq\n",
    "    inds = (fx<=fM)&(fx>=fm)\n",
    "    f=fx[inds]\n",
    "    Pxx_denX=Pxx_denX[inds]\n",
    "    Pxx_denY=Pxx_denY[inds]\n",
    "    Pxx_denZ=Pxx_denZ[inds]\n",
    "    Pxx_den = {'PSD_X':Pxx_denX,'PSD_Y':Pxx_denY,'PSD_Z':Pxx_denY}\n",
    "    Pxxdf = pd.DataFrame(data=Pxx_den,index=f)\n",
    "\n",
    "    return Pxxdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction131(clip_data):\n",
    "    \"\"\"\n",
    "    Extract features from both sensors (accel and gyro) for current clips and trials\n",
    "    Input: dictionary of clips from each subject\n",
    "    Output: feature matrix from all clips from given subject and scores for each clip\n",
    "    Column names separate for acc and gyro data.\n",
    "    \"\"\"\n",
    "    \n",
    "    features_list = ['meanX','meanY','meanZ','rangeX','rangeY','rangeZ','iqrX','iqrY','iqrZ',\n",
    "                     'stddev_X','stddev_Y','stddev_Z','skewX','skewY','skewZ','kurtX','kurtY','kurtZ',\n",
    "                     'hist1_X','hist2_X','hist3_X','hist4_X',\n",
    "                     'hist1_Y','hist2_Y','hist3_Y','hist4_Y',\n",
    "                     'hist1_Z','hist2_Z','hist3_Z','hist4_Z',\n",
    "                     #Moments of derivative: mean, SD, skew, kurtosis\n",
    "                     'mean_derivative_x','mean_derivative_y','mean_derivative_z',\n",
    "                     'std_derivative_x','std_derivative_y','std_derivative_z',\n",
    "                     'skew_derivative_x','skew_derivative_y','skew_derivative_z',\n",
    "                     'kurt_derivative_x','kurt_derivative_y','kurt_derivative_z',\n",
    "                     'mean_squared_norm','sum_stddev',\n",
    "                     'xcorr_XY','xcorr_XZ','xcorr_YZ',\n",
    "                     'crossprod_raw_xy','crossprod_raw_xz','crossprod_raw_yz',\n",
    "                     'crossprod_norm_xy','crossprod_norm_xz','crossprod_norm_yz',\n",
    "                     'abs_crossprod_raw_xy','abs_crossprod_raw_xz','abs_crossprod_raw_yz',\n",
    "                     'abs_crossprod_norm_xy','abs_crossprod_norm_xz','abs_crossprod_norm_yz',\n",
    "                     'PSD_mean_X','PSD_mean_Y','PSD_mean_Z',\n",
    "                     'PSD_std_X','PSD_std_Y','PSD_std_Z',\n",
    "                     'PSD_skew_X','PSD_skew_Y','PSD_skew_Z',\n",
    "                     'PSD_kur_X','PSD_kur_Y','PSD_kur_Z',\n",
    "                     # mean power 20 bins\n",
    "                     # x axis\n",
    "                     'meanpower_bin1_x','meanpower_bin2_x','meanpower_bin3_x','meanpower_bin4_x',\n",
    "                     'meanpower_bin5_x','meanpower_bin6_x','meanpower_bin7_x','meanpower_bin8_x',\n",
    "                     'meanpower_bin9_x','meanpower_bin10_x','meanpower_bin11_x','meanpower_bin12_x',\n",
    "                     'meanpower_bin13_x','meanpower_bin14_x','meanpower_bin15_x','meanpower_bin16_x',\n",
    "                     'meanpower_bin17_x','meanpower_bin18_x','meanpower_bin19_x','meanpower_bin20_x',\n",
    "                     # y axis\n",
    "                     'meanpower_bin1_y','meanpower_bin2_y','meanpower_bin3_y','meanpower_bin4_y',\n",
    "                     'meanpower_bin5_y','meanpower_bin6_y','meanpower_bin7_y','meanpower_bin8_y',\n",
    "                     'meanpower_bin9_y','meanpower_bin10_y','meanpower_bin11_y','meanpower_bin12_y',\n",
    "                     'meanpower_bin13_y','meanpower_bin14_y','meanpower_bin15_y','meanpower_bin16_y',\n",
    "                     'meanpower_bin17_y','meanpower_bin18_y','meanpower_bin19_y','meanpower_bin20_y',\n",
    "                     # z axis\n",
    "                     'meanpower_bin1_z','meanpower_bin2_z','meanpower_bin3_z','meanpower_bin4_z',\n",
    "                     'meanpower_bin5_z','meanpower_bin6_z','meanpower_bin7_z','meanpower_bin8_z',\n",
    "                     'meanpower_bin9_z','meanpower_bin10_z','meanpower_bin11_z','meanpower_bin12_z',\n",
    "                     'meanpower_bin13_z','meanpower_bin14_z','meanpower_bin15_z','meanpower_bin16_z',\n",
    "                     'meanpower_bin17_z','meanpower_bin18_z','meanpower_bin19_z','meanpower_bin20_z',]\n",
    "    acclist = [s + '_acc' for s in features_list]\n",
    "    gyrlist = [s + '_gyr' for s in features_list]\n",
    "\n",
    "    for trial in clip_data.keys():\n",
    "\n",
    "        for sensor in clip_data[trial].keys():\n",
    "\n",
    "            #cycle through all clips for current trial and save dataframe of features for current trial and sensor\n",
    "            features = []\n",
    "            for c in range(len(clip_data[trial][sensor]['data'])):\n",
    "                rawdata = clip_data[trial][sensor]['data'][c]\n",
    "\n",
    "                ######################\n",
    "                # Time domain features\n",
    "                ######################\n",
    "                #range on each axis\n",
    "                min_xyz = np.min(rawdata,axis=0)\n",
    "                max_xyz = np.max(rawdata,axis=0)\n",
    "                r = np.asarray(max_xyz-min_xyz)\n",
    "\n",
    "                #Moments on each axis - mean, std dev, skew, kurtosis\n",
    "                mean = np.asarray(np.mean(rawdata,axis=0))\n",
    "                std = np.asarray(np.std(rawdata,axis=0))\n",
    "                sk = skew(rawdata)\n",
    "                kurt = kurtosis(rawdata)\n",
    "\n",
    "                #Cross-correlation between axes pairs\n",
    "# Which mode?\n",
    "#                 xcorr_xy = np.correlate(rawdata.iloc[:,0],rawdata.iloc[:,1],mode='same')\n",
    "#                 xcorr_xz = np.correlate(rawdata.iloc[:,0],rawdata.iloc[:,2],mode='same')\n",
    "#                 xcorr_yz = np.correlate(rawdata.iloc[:,1],rawdata.iloc[:,2],mode='same')\n",
    "                xcorr_xy = np.correlate(rawdata.iloc[:,0],rawdata.iloc[:,1])\n",
    "                xcorr_xz = np.correlate(rawdata.iloc[:,0],rawdata.iloc[:,2])\n",
    "                xcorr_yz = np.correlate(rawdata.iloc[:,1],rawdata.iloc[:,2])\n",
    "#                 xcorr = np.array([xcorr_xy, xcorr_xz, xcorr_yz])\n",
    "                xcorr = np.array([xcorr_xy[0], xcorr_xz[0], xcorr_yz[0]])\n",
    "\n",
    "################\n",
    "# Added features\n",
    "################\n",
    "# after adding new features...\n",
    "# check names in features_list at top\n",
    "# and concatenate at end\n",
    "\n",
    "                # interquartile range\n",
    "                iqrange = iqr(rawdata,axis=0)\n",
    "                # histogram of z-score values\n",
    "                hist_z_scores_x = np.histogram(zscore(rawdata.iloc[:,0],axis=0), bins=4, range=(-2,2))\n",
    "                hist_z_scores_y = np.histogram(zscore(rawdata.iloc[:,1],axis=0), bins=4, range=(-2,2))\n",
    "                hist_z_scores_z = np.histogram(zscore(rawdata.iloc[:,2],axis=0), bins=4, range=(-2,2))\n",
    "#                 hist_z_scores = np.array([hist_z_scores_x, hist_z_scores_y, hist_z_scores_z])\n",
    "                hist_z_scores = np.concatenate((hist_z_scores_x[0], hist_z_scores_y[0], hist_z_scores_z[0]), axis=None)\n",
    "                \n",
    "# Derivative vs differences (matlab code uses differences instead of derivative)\n",
    "#                 differences = np.diff(rawdata,axis=0)\n",
    "#                 # mean of differences\n",
    "#                 mean_diff = np.asarray(np.mean(differences,axis=0))\n",
    "#                 # std dev of differences\n",
    "#                 std_diff = np.asarray(np.std(differences,axis=0))\n",
    "#                 # skewness of differences\n",
    "#                 skew_diff = skew(differences)\n",
    "#                 # kurtosis of differences\n",
    "#                 kurt_diff = kurtosis(differences)\n",
    "                ##############################\n",
    "                # derivative - for 3 axis\n",
    "#                 derivative = difference/32\n",
    "                derivativex = np.gradient(rawdata.iloc[:,0],32)\n",
    "                derivativey = np.gradient(rawdata.iloc[:,1],32)\n",
    "                derivativez = np.gradient(rawdata.iloc[:,2],32)\n",
    "                derivative = np.array([derivativex,derivativey,derivativez])\n",
    "                # derivative = np.gradient(rawdata, 32)\n",
    "                # mean of derivative\n",
    "                mean_derivative = np.mean(derivative,axis=1)\n",
    "                # std dev of derivative\n",
    "                std_derivative = np.std(derivative,axis=1)\n",
    "                # skewness of derivative\n",
    "                skew_derivative = skew(derivative,axis=1)\n",
    "                # kurtosis of derivative\n",
    "                kurt_derivative = kurtosis(derivative,axis=1)\n",
    "#                 moments_of_derivative = np.array([mean_derivative,std_derivative,skew_derivative,kurt_derivative])\n",
    "                moments_of_derivative = np.concatenate((mean_derivative,std_derivative,skew_derivative,kurt_derivative), axis=None)\n",
    "                \n",
    "                # sum of xyz std dev\n",
    "#                 sum_stddev = np.std(rawdata.iloc[:,0] + np.std(rawdata.iloc[:,1]) + np.std(rawdata.iloc[:,2]))\n",
    "                sum_stddev = np.array([np.std(rawdata.iloc[:,0] + np.std(rawdata.iloc[:,1]) + np.std(rawdata.iloc[:,2]))])\n",
    "                \n",
    "                # mean of the squared norm\n",
    "\n",
    "# How should I get the Euclidiean norm?\n",
    "#                 mean_of_squares = np.mean(np.mean(rawdata**2,axis=0)) # equation from matlab code - looks weird\n",
    "# Is degree of freedom n (for mean) or (n-1)?\n",
    "# Should be 1 feature\n",
    "#                 norm = np.sqrt(np.square(rawdata).sum(axis=0))\n",
    "#                 mean_squared_norm = np.mean(np.square(norm),axis=0)\n",
    "\n",
    "                # Default axis=1, independently normalize each sample, otherwise (if 0) normalize each feature.\n",
    "                norm = preprocessing.normalize(rawdata)\n",
    "#                 mean_squared_norm = np.mean(np.square(norm))\n",
    "                mean_squared_norm = np.array([np.mean(np.square(norm))])\n",
    "    \n",
    "\n",
    "#                 # normalize values (divided by acc norm) to get cross products\n",
    "#                 norm = rawdata / np.linalg.norm(rawdata) # rawdata / np.linalg.norm(rawdata)\n",
    "                # norm = rawdata/np.abs(np.sum(rawdata))\n",
    "    \n",
    "\n",
    "#                 # normalize values (divided by acc norm) to get cross products\n",
    "#                 norm = rawdata / np.linalg.norm(rawdata) # rawdata / np.linalg.norm(rawdata)\n",
    "                # norm = rawdata/np.abs(np.sum(rawdata))\n",
    "#                 crossprod_norm_xy = np.nanmean(norm.iloc[:,0])*norm.iloc[:,1]\n",
    "#                 crossprod_norm_xz = np.nanmean(norm.iloc[:,0])*norm.iloc[:,2]\n",
    "#                 crossprod_norm_yz = np.nanmean(norm.iloc[:,1])*norm.iloc[:,2]\n",
    "                crossprod_norm_xy = np.nanmean(norm[0]*norm[1])\n",
    "                crossprod_norm_xz = np.nanmean(norm[0]*norm[2])\n",
    "                crossprod_norm_yz = np.nanmean(norm[1]*norm[2])\n",
    "                abs_crossprod_norm_xy = np.abs(crossprod_norm_xy)\n",
    "                abs_crossprod_norm_xz = np.abs(crossprod_norm_xz)\n",
    "                abs_crossprod_norm_yz = np.abs(crossprod_norm_yz)\n",
    "                crossprod_raw_xy = np.nanmean(rawdata.iloc[:,0]*rawdata.iloc[:,1])\n",
    "                crossprod_raw_xz = np.nanmean(rawdata.iloc[:,0]*rawdata.iloc[:,2])\n",
    "                crossprod_raw_yz = np.nanmean(rawdata.iloc[:,1]*rawdata.iloc[:,2])\n",
    "                abs_crossprod_raw_xy = np.abs(crossprod_raw_xy)\n",
    "                abs_crossprod_raw_xz = np.abs(crossprod_raw_xz)\n",
    "                abs_crossprod_raw_yz = np.abs(crossprod_raw_yz)\n",
    "                crossprod = np.array([crossprod_raw_xy, crossprod_raw_xz, crossprod_raw_yz,\n",
    "                                      crossprod_norm_xy, crossprod_norm_xz, crossprod_norm_yz,\n",
    "                                      abs_crossprod_raw_xy, abs_crossprod_raw_xz, abs_crossprod_raw_yz,\n",
    "                                      abs_crossprod_norm_xy, abs_crossprod_norm_xz, abs_crossprod_norm_yz])\n",
    "                \n",
    "                # sum of xyz std dev\n",
    "#                 sum_stddev = np.std(rawdata.iloc[:,0] + np.std(rawdata.iloc[:,1]) + np.std(rawdata.iloc[:,2]))\n",
    "                sum_stddev = np.array([np.std(rawdata.iloc[:,0] + np.std(rawdata.iloc[:,1]) + np.std(rawdata.iloc[:,2]))])\n",
    "                \n",
    "# What is this? Omit?               \n",
    "#                 # Linear fit\n",
    "#                 slope_xy = np.polyfit(rawdata.iloc[:,0],rawdata.iloc[:,1],1)[0]\n",
    "#                 slope_xz = np.polyfit(rawdata.iloc[:,0],rawdata.iloc[:,2],1)[0]\n",
    "#                 slope_yz = np.polyfit(rawdata.iloc[:,1],rawdata.iloc[:,2],1)[0]\n",
    "\n",
    "                # power spectral density (PSD)\n",
    "                Pxx = power_spectra_welch_axis(rawdata,fm=0,fM=10)\n",
    "                #moments of PSD\n",
    "#                 Pxx_moments = np.array([np.nanmean(Pxx.iloc[0].values),np.nanmean(Pxx.iloc[1].values),np.nanmean(Pxx.iloc[2].values),\n",
    "#                                         np.nanstd(Pxx.iloc[0].values),np.nanstd(Pxx.iloc[1].values),np.nanstd(Pxx.iloc[2].values),\n",
    "#                                         skew(Pxx.iloc[0].values),skew(Pxx.iloc[1].values),skew(Pxx.iloc[2].values),\n",
    "#                                         kurtosis(Pxx.iloc[0].values),kurtosis(Pxx.iloc[1].values),kurtosis(Pxx.iloc[2].values)])\n",
    "                Pxx_moments = np.array([np.nanmean(Pxx.iloc[:,0].values),np.nanmean(Pxx.iloc[:,1].values),np.nanmean(Pxx.iloc[:,2].values),\n",
    "                        np.nanstd(Pxx.iloc[:,0].values),np.nanstd(Pxx.iloc[:,1].values),np.nanstd(Pxx.iloc[:,2].values),\n",
    "                        skew(Pxx.iloc[:,0].values),skew(Pxx.iloc[:,1].values),skew(Pxx.iloc[:,2].values),\n",
    "                        kurtosis(Pxx.iloc[:,0].values),kurtosis(Pxx.iloc[:,1].values),kurtosis(Pxx.iloc[:,2].values)])\n",
    "                # Mean power in 0.5 Hz bins between 0 and 10 Hz (x, y, z)\n",
    "                binedges = np.arange(0,10.5,0.5)\n",
    "                powerbin_df = Pxx.groupby(pd.cut(Pxx.index, bins=binedges)).mean().fillna(0)\n",
    "#                 powerbinarray = np.asarray((powerbin_df.iloc[:,0],powerbin_df.iloc[:,1],powerbin_df.iloc[:,2]))\n",
    "                powerbinarray = np.concatenate((powerbin_df.iloc[:,0],powerbin_df.iloc[:,1],powerbin_df.iloc[:,2]), axis=None)\n",
    "#####################################\n",
    "############## End of added features\n",
    "#####################################\n",
    "\n",
    "                #Assemble features in array\n",
    "# make sure all the columns add up and are labeled\n",
    "#                 X = np.concatenate((mean,r,iqrange,std,sk,kurt,hist_z_scores,moments_of_derivative,mean_squared_norm,sum_stddev,\n",
    "#                                     xcorr,crossprod,Pxx_moments,powerbinarray))\n",
    "                X = np.concatenate((mean,r,iqrange,std,sk,kurt,hist_z_scores,moments_of_derivative,mean_squared_norm,sum_stddev,\n",
    "                    xcorr,crossprod,Pxx_moments,powerbinarray))\n",
    "                features.append(X)\n",
    "\n",
    "            F = np.asarray(features) #feature matrix for all clips from current trial\n",
    "        #     clip_data['features'] = pd.DataFrame(data=F,columns=features_list,dtype='float32')\n",
    "            if sensor == 'accel': columns_list = acclist\n",
    "            else: columns_list = gyrlist\n",
    "            try:\n",
    "                clip_data[trial][sensor]['features'] = pd.DataFrame(data=F,columns=columns_list,dtype='float32')\n",
    "            except:\n",
    "                print('Empty data in feature_extraction131')\n",
    "                continue\n",
    "#     return clip_data #not necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
